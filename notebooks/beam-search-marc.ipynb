{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e2725cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T14:28:48.190636247Z",
     "start_time": "2024-05-06T14:28:46.367331409Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/riyadh/codes/nlp/learningtoask-final/venv/lib64/python3.10/site-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/home/riyadh/codes/nlp/learningtoask-final/venv/lib64/python3.10/site-packages/torchtext/utils.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "# %load_ext jupyter_black\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from src.trainutil import *\n",
    "\n",
    "import yaml\n",
    "\n",
    "data_root = \"../data\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fbf6a2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T14:28:56.991954615Z",
     "start_time": "2024-05-06T14:28:56.942277952Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment_dir = Path(\"../checkpoints/paper\")\n",
    "with open(experiment_dir / \"history/config.yaml\", \"r\") as stream:\n",
    "    cfg = yaml.safe_load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afb0010d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T14:28:59.198933801Z",
     "start_time": "2024-05-06T14:28:59.047974915Z"
    }
   },
   "outputs": [],
   "source": [
    "src_tokenizer = torch.load(experiment_dir / \"src_tokenizer.pt\")\n",
    "tgt_tokenizer = torch.load(experiment_dir / \"tgt_tokenizer.pt\")\n",
    "src_vocab = src_tokenizer.vocab\n",
    "tgt_vocab = tgt_tokenizer.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5bf4826",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T14:30:15.322640480Z",
     "start_time": "2024-05-06T14:30:14.897258957Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Seq2Seq(\n  (src_embedding): Embedding(45000, 300)\n  (tgt_embedding): Embedding(28000, 300)\n  (encoder): Encoder(\n    (embedding): Embedding(45000, 300)\n    (layers): Sequential(\n      (0): Embedding(45000, 300)\n      (1): LSTM(300, 600, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n    )\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(28000, 300)\n    (lstm): LSTM(300, 600, num_layers=2, batch_first=True, dropout=0.3)\n    (attention): Attention(\n      (projection_layer): Linear(in_features=1200, out_features=600, bias=True)\n    )\n    (decoder_linear): Sequential(\n      (0): Linear(in_features=1800, out_features=600, bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=600, out_features=28000, bias=True)\n    )\n  )\n)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Seq2Seq(\n",
    "    src_vocab_size=len(src_vocab),\n",
    "    tgt_vocab_size=len(tgt_vocab),\n",
    "    src_embedding_vector=None,\n",
    "    tgt_embedding_vector=None,\n",
    "    tgt_pad_index=tgt_vocab[\"<PAD>\"],\n",
    "    tgt_sos_index=tgt_vocab[\"<SOS>\"],\n",
    "    tgt_eos_index=tgt_vocab[\"<EOS>\"],\n",
    "    hidden_size=cfg[\"hidden_size\"],\n",
    "    bidirectional=cfg[\"bidirectional\"],\n",
    "    num_layers=cfg[\"num_layers\"],\n",
    "    src_embedding_size=cfg[\"src_embedding_size\"],\n",
    "    tgt_embedding_size=cfg[\"tgt_embedding_size\"],\n",
    "    dropout=cfg[\"dropout\"],\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a8a0c04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T14:30:16.732073297Z",
     "start_time": "2024-05-06T14:30:16.454063289Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 16:30:16,667 ðŸŽ‰ Loaded existing model. Epoch: 13\n"
     ]
    }
   ],
   "source": [
    "model, _, _, epoch = load_checkpoint(model, experiment_dir / \"model_best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "with open(f\"{data_root}/dev.src\") as srcfile:\n",
    "    sources = srcfile.readlines()\n",
    "\n",
    "with open(f\"{data_root}/dev.tgt\") as tgtfile:\n",
    "    references = tgtfile.readlines()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T16:18:00.795871798Z",
     "start_time": "2024-05-06T16:18:00.746721884Z"
    }
   },
   "id": "d0ce3f9eef79a484"
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "def beam_search(module: nn.Module, src_token2index, trg_vocab, trg_edge_index, src_tokens, src_mask, max_len,\n",
    "                  beam_size):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model: \n",
    "        src_token2index: dict\n",
    "        src_pad_index:  int\n",
    "        trg_vocab: list\n",
    "        trg_edge_index: int \n",
    "        src_tokens: ['I', 'hate', 'it', '.']\n",
    "        max_len: int\n",
    "        beam_size: int\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    # (1, src_seq)\n",
    "    src_indexed = torch.tensor(\n",
    "        [[src_token2index[token] for token in src_tokens]],\n",
    "        dtype=torch.int64, device=device\n",
    "    )\n",
    "\n",
    "    # (1,1)\n",
    "    # beam_prefixes_indexed = torch.tensor([[trg_edge_index]], dtype=torch.int64, device=device)\n",
    "    beam_prefixes_indexed = torch.full(\n",
    "        (1, 1), module.tgt_sos_index, device=device, dtype=torch.long\n",
    "    )\n",
    "    # (1, )\n",
    "    beam_prefixes_probs = np.array([1.0], np.float32)\n",
    "\n",
    "    best_full_prefix_indexed = None\n",
    "    best_full_prefix_prob = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        encoder_out, h = module.encoder(src_indexed)\n",
    "        h = h[: module.num_layers]\n",
    "        c = torch.zeros_like(h, device=device)\n",
    "        \n",
    "        for t in range(max_len):\n",
    "            # print(encoder_out.shape, h.shape, c.shape, beam_prefixes_indexed.shape)\n",
    "            if t == 1:\n",
    "                h = h.tile(1, beam_prefixes_indexed.size(0), 1)\n",
    "                c = c.tile(1, beam_prefixes_indexed.size(0), 1)\n",
    "            output, (h, c), _ = module.decoder(\n",
    "                encoder_out, beam_prefixes_indexed[:, -1].view(-1, 1), h, c, src_mask\n",
    "            )\n",
    "\n",
    "            # (beam_size, tgt_vocab_size)\n",
    "            token_probs = output.squeeze(-1)\n",
    "            # (beam_size, tgt_vocab)  = (1, 1) * (beam_size, tgt_vocab)\n",
    "            new_prefixes_probs = beam_prefixes_probs[:, None] * token_probs.cpu().numpy()\n",
    "            new_partial_prefixes = []\n",
    "            for (prefix, probs_group) in zip(beam_prefixes_indexed.cpu().tolist(), new_prefixes_probs.tolist()):\n",
    "                # single token_id, token_prob\n",
    "                for (next_token_index, prefix_prob) in enumerate(probs_group):\n",
    "                    if next_token_index == trg_edge_index:\n",
    "                        if best_full_prefix_prob is None or prefix_prob > best_full_prefix_prob:\n",
    "                            best_full_prefix_indexed = prefix + [next_token_index]\n",
    "                            best_full_prefix_prob = prefix_prob\n",
    "                    else:\n",
    "                        new_partial_prefixes.append((prefix_prob, prefix + [next_token_index]))\n",
    "\n",
    "            new_partial_prefixes.sort(reverse=True)\n",
    "            (best_partial_prefix_prob, _) = new_partial_prefixes[0]\n",
    "            if best_full_prefix_prob > best_partial_prefix_prob:\n",
    "                text = [trg_vocab[index] for index in best_full_prefix_indexed]\n",
    "                return (text, best_full_prefix_prob)\n",
    "\n",
    "            new_beam = new_partial_prefixes[:beam_size]\n",
    "            beam_prefixes_indexed = torch.tensor([prefix for (prob, prefix) in new_beam], dtype=torch.int64,\n",
    "                                                 device=device)\n",
    "            beam_prefixes_probs = np.array([prob for (prob, prefix) in new_beam], np.float32)\n",
    "            \n",
    "\n",
    "    text = [trg_vocab[index] for index in beam_prefixes_indexed[0, :].cpu().tolist()]\n",
    "    return text, beam_prefixes_probs[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T16:38:09.678344517Z",
     "start_time": "2024-05-06T16:38:09.637857588Z"
    }
   },
   "id": "2bef9c676f600dc6"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the american football conference -lrb- afc -rrb- champion denver broncos defeated the national football conference -lrb- nfc -rrb- champion carolina panthers 24 -- 10 to earn their third super bowl title . \n",
      "\n",
      "which nfl team represented the afc at super bowl 50 ?\n"
     ]
    }
   ],
   "source": [
    "print(sources[0], references[0], sep='\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T16:11:12.829648303Z",
     "start_time": "2024-05-06T16:11:12.795184660Z"
    }
   },
   "id": "21e4fbb5fa470a88"
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "(['<SOS>',\n  'what',\n  'type',\n  'of',\n  'the',\n  'church',\n  'want',\n  'to',\n  '<UNK>',\n  'the',\n  '<UNK>',\n  '<UNK>',\n  '<EOS>'],\n 8593216634880.0)"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_token_ids, src_mask = src_tokenizer.encode(\n",
    "        sources[0], max_seq=cfg[\"src_max_seq\"]\n",
    "    )\n",
    "src_token_ids = src_token_ids.to(device)\n",
    "src_mask = src_mask.to(device)\n",
    "beam_search(module=model,\n",
    "              src_token2index=tgt_vocab,\n",
    "              trg_vocab=tgt_vocab.get_itos(),\n",
    "              trg_edge_index=tgt_vocab['<EOS>'],\n",
    "              src_tokens=sources[0].split(),\n",
    "              src_mask=src_mask,\n",
    "              max_len=14,\n",
    "              beam_size=3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T16:24:20.194078458Z",
     "start_time": "2024-05-06T16:24:15.658583040Z"
    }
   },
   "id": "b19be5994ffa63c3"
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "following the election of the uk labour party to government in 1997 , the uk formally subscribed to the agreement on social policy , which allowed it to be included with minor amendments as the social chapter of the 1997 treaty of amsterdam . \n",
      "\n",
      "\n",
      "when did the uk formally subscribe to the agreement on social policy ?\n",
      "\n",
      "[\"who rejected the fbi 's law to the protest ?\", 'what government party was the european parliament under the soviet agreement']\n"
     ]
    }
   ],
   "source": [
    "idx = random.randint(0, 10000)\n",
    "# nucleus\n",
    "hyp_nucleus, _ = generate(model, sources[idx: idx+2], src_tokenizer, tgt_tokenizer, cfg, method=\"nucleus\", p=0.6)\n",
    "\n",
    "print(sources[idx], references[idx], sep='\\n\\n')\n",
    "# print(f\"nucleus: {hyp_nucleus[0]}\\n\\nbeam: {hyp_beam}\\n\\ngreedy: {hyp_greedy}\\nbeam marc: {hyp_beam_marc}\")\n",
    "print(hyp_nucleus)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T17:22:14.789414533Z",
     "start_time": "2024-05-06T17:22:14.481911940Z"
    }
   },
   "id": "d0ef43f7b7adfd06"
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T17:14:15.920784034Z",
     "start_time": "2024-05-06T17:14:15.911407191Z"
    }
   },
   "id": "1c71abd5f9e92df2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
