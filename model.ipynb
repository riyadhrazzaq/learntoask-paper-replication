{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c81669ff-f9fe-499e-b412-33ad42c823ec",
   "metadata": {},
   "source": [
    "# Global Attention Mechanism\n",
    "*Effective Approaches to Attention-based Neural Machine Translation by Luong et. el.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "569afcc5-1d8d-40b1-bc63-396530c15322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "from torchtext.vocab import GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24ea83fe-06ad-4a05-ac20-db3bbb038bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = GloVe(name='840B', cache='data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4913e46e-f0d1-42f4-8dc0-fcc6657e7e19",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/codes/nlp/learn2ask/venv/lib64/python3.9/site-packages/torch/nn/modules/sparse.py:211\u001b[0m, in \u001b[0;36mEmbedding.from_pretrained\u001b[0;34m(cls, embeddings, freeze, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pretrained\u001b[39m(\u001b[38;5;28mcls\u001b[39m, embeddings, freeze\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, padding_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    183\u001b[0m                     max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, norm_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2.\u001b[39m, scale_grad_by_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    184\u001b[0m                     sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    185\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Create Embedding instance from given 2-dimensional FloatTensor.\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;124;03m        tensor([[ 4.0000,  5.1000,  6.3000]])\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m, \\\n\u001b[1;32m    212\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmbeddings parameter is expected to be 2-dimensional\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    213\u001b[0m     rows, cols \u001b[38;5;241m=\u001b[39m embeddings\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    214\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\n\u001b[1;32m    215\u001b[0m         num_embeddings\u001b[38;5;241m=\u001b[39mrows,\n\u001b[1;32m    216\u001b[0m         embedding_dim\u001b[38;5;241m=\u001b[39mcols,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    222\u001b[0m         scale_grad_by_freq\u001b[38;5;241m=\u001b[39mscale_grad_by_freq,\n\u001b[1;32m    223\u001b[0m         sparse\u001b[38;5;241m=\u001b[39msparse)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "nn.Embedding.from_pretrained(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f26d448-f468-497e-8dd1-54f457d30a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, embedding_dim=50, hidden_dim=4, bidirectional=False):\n",
    "        self.embedding = nn.Embedding.from_pretrained()\n",
    "        \n",
    "        self.encoder = nn.LSTM(input_size=embedding_dim, \n",
    "                               hidden_size=hidden_dim,\n",
    "                               batch_first=True,\n",
    "                               bidirectional=bidirectional)\n",
    "\n",
    "        self.decoder = nn.LSTM(input_size=embedding_dim, \n",
    "                              hidden_size=hidden_dim, \n",
    "                              batch_first=True,\n",
    "                              bidirectional=False)\n",
    "\n",
    "        self.attn_linear = nn.Linear(in_features=hidden_dim,\n",
    "                                    out_features=hidden_dim)\n",
    "\n",
    "\n",
    "    def forward(self, source):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        source: torch.Tensor. \n",
    "        \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
