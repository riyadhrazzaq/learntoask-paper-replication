# Todo
[x] simple training for single training
[] modify for batch and support padding
[] add beam search decoding in `decoder` step of the model
[] initiate the decoder hidden states with last step of encoder hidden states
[] ignore padding in attention
[] make decoder lstm bidirectional
[] write detail of the attention mechanism
[] visualize attention matrices
