{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc316950-16f5-4ca6-8f18-9a4d7866f79d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268e3b66-9ae5-4c43-88a2-5d992356bdc9",
   "metadata": {},
   "source": [
    "https://pytorch.org/tutorials/beginner/chatbot_tutorial.html?highlight=chatbot#define-evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0cdea6-8371-4cc7-9254-ef7e69caa92b",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f28a4050-5bbf-4677-b41e-ef8f7ceb75e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/riyadh/codes/nlp/learn2ask/venv/lib64/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import io\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torchtext\n",
    "from torchtext.vocab import build_vocab_from_iterator, GloVe\n",
    "from nltk.translate import bleu\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d2cfc4-0e3e-4119-ad96-ad8da9126fa0",
   "metadata": {},
   "source": [
    "# Look at Data\n",
    "Data already preprocessed collected from the original repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73e4df45-47bd-4670-9ddc-c02866e8f9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = Path(\"data/processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dd7c3bc-bffd-4c4b-a699-ca7b1f12c505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70484 70484\n"
     ]
    }
   ],
   "source": [
    "with open(data_root / \"src-train.txt\") as f:\n",
    "    _sentences = f.readlines()\n",
    "\n",
    "with open(data_root / \"tgt-train.txt\") as f:\n",
    "    _questions = f.readlines()\n",
    "\n",
    "print(len(_sentences), len(_questions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898e4fe2-49a3-49a7-be64-d097fea0d979",
   "metadata": {},
   "source": [
    "# Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11f2e760-9b15-421a-83bf-6dd8d4476ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_token(text_file_path):\n",
    "    with io.open(text_file_path, encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            yield line.strip().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "881a0495-7105-4dd5-9ad2-55ab29bd91a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 778 ms, sys: 91.1 ms, total: 869 ms\n",
      "Wall time: 862 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentence_vocab = build_vocab_from_iterator(\n",
    "    yield_token(data_root / \"src-train.txt\"),\n",
    "    max_tokens=45000,\n",
    "    specials=[\"<SOS>\", \"<EOS>\", \"<PAD>\", \"<UNK>\"],\n",
    "    special_first=True,\n",
    ")\n",
    "\n",
    "question_vocab = build_vocab_from_iterator(\n",
    "    yield_token(data_root / \"tgt-train.txt\"), max_tokens=28000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad1693ea-dba6-471c-889f-f5f211578744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49823\n"
     ]
    }
   ],
   "source": [
    "# merge two vocabs once collected from separate corpus\n",
    "vocab = torchtext.vocab.Vocab(sentence_vocab)\n",
    "vocab.set_default_index(vocab[\"<UNK>\"])\n",
    "\n",
    "for token in question_vocab.get_itos():\n",
    "    if token not in vocab:\n",
    "        vocab.append_token(token)\n",
    "\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57a20090-928c-4c2c-8413-a047c5ba7f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vector = torch.zeros(size=(len(vocab), 300))\n",
    "glove = GloVe(cache=\"data/\")\n",
    "for index in range(len(vocab)):\n",
    "    embedding_vector[index] = glove[vocab.lookup_token(index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59edf048-0115-4d44-995b-44918b98be8c",
   "metadata": {},
   "source": [
    "# Batch Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "023146f9-a3be-48bb-b09f-53192e2494c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"sentence_max_length\": 150, \"question_max_length\": 50, \"batch_size\": 32}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70fdf903-14d4-458a-9e6e-5c19f7a3a610",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceQuestionDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab: torchtext.vocab.Vocab,\n",
    "        sentences: List[str],\n",
    "        questions: List[str],\n",
    "        Ls=150,\n",
    "        Lq=50,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Represents a dataset of text pairs for training or evaluating models that\n",
    "        deal with relationships between text passages.\n",
    "\n",
    "        Args:\n",
    "            vocab (torchtext.vocab.Vocab): A pre-built vocabulary object\n",
    "                containing word mappings from text to numerical representation.\n",
    "            sentences (List[str]): A list of text passages (sentences, paragraphs, etc.).\n",
    "            questions (List[str]): A list of corresponding questions related to the sentences.\n",
    "            Ls (int, optional): The maximum length to which sentences will be\n",
    "                truncated or padded during preprocessing (default: 150).\n",
    "            Lq (int, optional): The maximum length to which questions will be\n",
    "                truncated or padded during preprocessing (default: 50).\n",
    "        \"\"\"\n",
    "        self.pad_index = vocab[\"<PAD>\"]\n",
    "        self.sos_index = vocab[\"<SOS>\"]\n",
    "        self.eos_index = vocab[\"<EOS>\"]\n",
    "\n",
    "        sentences_indexed = [vocab(document.split()) for document in sentences]\n",
    "        questions_indexed = [vocab(document.split()) for document in questions]\n",
    "\n",
    "        self.sentences_tensor = torch.full(\n",
    "            (len(sentences), Ls), self.pad_index, dtype=torch.long\n",
    "        )\n",
    "        self.questions_tensor = torch.full(\n",
    "            (len(questions), Lq), self.pad_index, dtype=torch.long\n",
    "        )\n",
    "\n",
    "        for i, data in enumerate(zip(sentences_indexed, questions_indexed)):\n",
    "            # clip sentence length to Ls and add <sos>, <eos>\n",
    "\n",
    "            _sentence_indices = (\n",
    "                data[0] if len(data[0]) <= (Ls - 2) else data[0][: (Ls - 2)]\n",
    "            )\n",
    "            _sentence_indices = (\n",
    "                [\n",
    "                    self.sos_index,\n",
    "                ]\n",
    "                + _sentence_indices\n",
    "                + [\n",
    "                    self.eos_index,\n",
    "                ]\n",
    "            )\n",
    "            ls = len(_sentence_indices)\n",
    "            self.sentences_tensor[i, :ls] = torch.tensor(_sentence_indices)\n",
    "\n",
    "            # clip question length to Lq and add <sos>, <eos>\n",
    "            _question_indices = (\n",
    "                data[1] if len(data[1]) <= (Lq - 2) else data[1][: (Lq - 2)]\n",
    "            )\n",
    "            _question_indices = (\n",
    "                [\n",
    "                    self.sos_index,\n",
    "                ]\n",
    "                + _question_indices\n",
    "                + [\n",
    "                    self.eos_index,\n",
    "                ]\n",
    "            )\n",
    "            # lq may or may not be equal to Lq\n",
    "            lq = len(_question_indices)\n",
    "            self.questions_tensor[i, :lq] = torch.tensor(_question_indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.sentences_tensor.size(0)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.sentences_tensor[index], self.questions_tensor[index])\n",
    "\n",
    "\n",
    "train_ds = SentenceQuestionDataset(\n",
    "    vocab,\n",
    "    _sentences,\n",
    "    _questions,\n",
    "    Ls=config[\"sentence_max_length\"],\n",
    "    Lq=config[\"question_max_length\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb93a8c4-5982-43d8-af21-98e960b42db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2203\n"
     ]
    }
   ],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "print(len(train_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61eee375-34d1-4d17-b425-82ae4af40d7b",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4ad731-20ca-4c71-8c5c-ad88aeb19203",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d204de4b-5c55-403d-bc06-e6da7a6342b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, vocab_size, embedding, embedding_dim, hidden_dim=8, bidirectional=False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = embedding\n",
    "        self.encoder = nn.Sequential(\n",
    "            self.embedding,\n",
    "            nn.LSTM(\n",
    "                input_size=embedding_dim,\n",
    "                hidden_size=hidden_dim,\n",
    "                batch_first=True,\n",
    "                bidirectional=bidirectional,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def forward(self, src: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src (torch.Tensor): (N, Ls) A batch of source sentences represented as tensors.\n",
    "        \"\"\"\n",
    "        # encoder_representation (N, Ls, d), hT => cT => (#direction * #layer, N, d) : hidden states from the last timestep\n",
    "        encoder_out, (last_hidden_state, last_cell_state) = self.encoder(src)\n",
    "        return encoder_out, (last_hidden_state, last_cell_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3cd212e-01cb-43d3-a140-2e2fa43f5e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Luong attention layer\n",
    "class Attn(nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        self.method = method\n",
    "        if self.method not in [\"dot\", \"general\", \"concat\"]:\n",
    "            raise ValueError(self.method, \"is not an appropriate attention method.\")\n",
    "        self.hidden_size = hidden_size\n",
    "        if self.method == \"general\":\n",
    "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
    "        elif self.method == \"concat\":\n",
    "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.v = nn.Parameter(torch.FloatTensor(hidden_size))\n",
    "\n",
    "    def dot_score(self, hidden, encoder_output):\n",
    "        return torch.sum(hidden * encoder_output, dim=2)\n",
    "\n",
    "    def general_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(encoder_output)\n",
    "        return torch.sum(hidden * energy, dim=2)\n",
    "\n",
    "    def concat_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(\n",
    "            torch.cat(\n",
    "                (hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2\n",
    "            )\n",
    "        ).tanh()\n",
    "        return torch.sum(self.v * energy, dim=2)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        # Calculate the attention weights (energies) based on the given method\n",
    "        if self.method == \"general\":\n",
    "            attn_energies = self.general_score(hidden, encoder_outputs)\n",
    "        elif self.method == \"concat\":\n",
    "            attn_energies = self.concat_score(hidden, encoder_outputs)\n",
    "        elif self.method == \"dot\":\n",
    "            attn_energies = self.dot_score(hidden, encoder_outputs)\n",
    "\n",
    "        # Transpose max_length and batch_size dimensions\n",
    "        # attn_energies = attn_energies.t()\n",
    "\n",
    "        # Return the softmax normalized probability scores (with added dimension)\n",
    "        return nn.functional.softmax(attn_energies, dim=1).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5ac35f1-7452-45bc-9394-38e6eeb5068c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from globalattention import Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0a41f1e1-7192-4669-8117-002a2ec14e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        embedding,\n",
    "        embedding_dim,\n",
    "        hidden_dim=8,\n",
    "        encoder_bidirectional=False,\n",
    "        num_layers=1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = embedding\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            batch_first=True,\n",
    "            bidirectional=False,\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "\n",
    "        # self.attn_layer = nn.Linear(\n",
    "        #     in_features=hidden_dim * 2 if bidirectional else hidden_dim,\n",
    "        #     out_features=hidden_dim * 2 if bidirectional else hidden_dim,\n",
    "        # )\n",
    "\n",
    "        self.attention = Attention(\n",
    "            hidden_dim * 2 if encoder_bidirectional else hidden_dim, hidden_dim\n",
    "        )\n",
    "\n",
    "        self.decoder_linear = nn.Sequential(\n",
    "            # 3*hidden_dim because decoder_out and source context will be concatenated\n",
    "            # this layer is Eq 5 in the Luong et. al. paper\n",
    "            nn.Linear(\n",
    "                hidden_dim * 3 if encoder_bidirectional else hidden_dim, hidden_dim\n",
    "            ),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, vocab_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, encoder_out, target, last_hidden_state, last_cell_state):\n",
    "        x = self.embedding(target)\n",
    "        # => N, 1, d\n",
    "        output, (ht, ct) = self.lstm(x, (last_hidden_state, last_cell_state))\n",
    "        # => (N, Ls, 1)\n",
    "        score = self.attention(encoder_out, output)\n",
    "        # (N, Ls, 1) x (N, Ls, DH) => (N, Ls, DH) => (N, 1, DH)\n",
    "        # Eq 4 from the Du et. al. paper (learning to ask)\n",
    "        attn_based_ctx = (score * encoder_out).sum(dim=1).unsqueeze(dim=1)\n",
    "        # => (N, 1, d ) & (N, 1, DH)\n",
    "        concatenated = torch.cat((output, attn_based_ctx), dim=2).squeeze()\n",
    "        # => (N, vocab_size)\n",
    "        logit = self.decoder_linear(concatenated)\n",
    "\n",
    "        return logit, (ht, ct), score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b7ec74b8-6ca5-4fd1-8bd7-c80776ff3ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 24])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.full((3, 5, 1), 0.5)\n",
    "b = torch.full((3, 5, 16), 2)\n",
    "c = (a * b).sum(dim=1).unsqueeze(dim=1)\n",
    "d = torch.cat((torch.randn((3, 1, 8)), c), dim=2)\n",
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8fb163df-31ad-474d-90ad-9fe9b7790863",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqEncoderDecoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        embedding_vector,\n",
    "        embedding_dim,\n",
    "        pad_index,\n",
    "        sos_index,\n",
    "        eos_index,\n",
    "        hidden_dim=8,\n",
    "        bidirectional=True,\n",
    "    ):\n",
    "\n",
    "        super().__init__()\n",
    "        self.sos_index = sos_index\n",
    "        self.pad_index = pad_index\n",
    "        self.eos_index = eos_index\n",
    "\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_vector)\n",
    "        self.encoder = Encoder(\n",
    "            vocab_size, self.embedding, embedding_dim, hidden_dim, bidirectional\n",
    "        )\n",
    "        self.decoder = Decoder(\n",
    "            vocab_size, self.embedding, embedding_dim, hidden_dim, bidirectional\n",
    "        )\n",
    "\n",
    "    def forward(self, source, target):\n",
    "        encoder_out, (h, c) = self.encoder(source)\n",
    "        h = h[:1]\n",
    "        c = c[:1]\n",
    "        max_seq = target.size(1)\n",
    "        logits = []\n",
    "        scores = []\n",
    "\n",
    "        for timestep in range(max_seq):\n",
    "            logit, (h, c), score = self.decoder(\n",
    "                encoder_out, target[:, timestep].unsqueeze(dim=1), h, c\n",
    "            )\n",
    "            logits.append(logit)\n",
    "            scores.append(score)\n",
    "\n",
    "        return logits, scores\n",
    "\n",
    "    def generate(self, source, max_seq=10):\n",
    "        encoder_out, (h, c) = self.encoder(source)\n",
    "        h = h[:1]\n",
    "        c = c[:1]\n",
    "        generated_seq = [\n",
    "            torch.tensor(\n",
    "                [self.sos_index for _ in range(source.size(0))], dtype=torch.long\n",
    "            )\n",
    "        ]\n",
    "        scores = []\n",
    "        for timestep in range(max_seq):\n",
    "            target = generated_seq[-1].view(-1, 1)\n",
    "            logit, (h, c), score = self.decoder(encoder_out, target, h, c)\n",
    "            scores.append(score)\n",
    "            most_probable_tokens = torch.max(logit, dim=1)[1]\n",
    "            generated_seq.append(most_probable_tokens)\n",
    "\n",
    "        return torch.concat(generated_seq, dim=0).view(source.size(0), -1), scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "572c9c58-25b2-49d3-86f4-a1ade20db7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 150])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 83,  17,  30, 111,  32])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn((5, 150))\n",
    "print(a.shape)\n",
    "torch.max(a, dim=1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b79ab52a-d0ab-40dd-bce8-4b1e77599eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                                                       | 6/2203 [00:16<1:43:09,  2.82s/batch, loss=3.21]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss 8.171118100484213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                                                       | 6/2203 [00:15<1:32:40,  2.53s/batch, loss=3.19]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 loss 3.870549281438192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f04f584cc70>]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train_epoch(model, optimizer, max_step=float(\"inf\")):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    total_loss = 0\n",
    "    bar = tqdm(train_dl, unit=\"batch\")\n",
    "\n",
    "    for step, data in enumerate(bar):\n",
    "        optimizer.zero_grad()\n",
    "        logits, scores = model(data[0], data[1])\n",
    "        final_logits = torch.cat(logits, dim=0).view(\n",
    "            logits[0].size(0), -1, logits[0].size(1)\n",
    "        )\n",
    "        loss = criterion(final_logits.transpose(1, 2), data[1])\n",
    "        bar.set_postfix(**{\"loss\": loss.item()})\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # early exit, needed during development\n",
    "        if step > max_step:\n",
    "            break\n",
    "\n",
    "    return total_loss / step\n",
    "\n",
    "\n",
    "model = Seq2SeqEncoderDecoder(\n",
    "    len(vocab),\n",
    "    embedding_vector,\n",
    "    300,\n",
    "    vocab[\"<PAD>\"],\n",
    "    vocab[\"<SOS>\"],\n",
    "    vocab[\"<EOS>\"],\n",
    "    8,\n",
    "    True,\n",
    ")\n",
    "optim = torch.optim.SGD(model.parameters(), lr=1.0)\n",
    "\n",
    "losses = []\n",
    "for i in range(1, 3):\n",
    "    loss = train_epoch(model, optim, max_step=5)\n",
    "    print(\"epoch\", i, \"loss\", loss)\n",
    "    losses.append(loss)\n",
    "\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a316814c-62f3-4593-b43c-5bbe36c983a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 11])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source = next(iter(train_dl))[0]\n",
    "torch.concat(model.generate(source)[0], dim=0).view(source.size(0), -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dcbe2ca5-9664-49e1-9b51-dd78227da610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[   0, 1876,   23,  ...,    2,    2,    2],\n",
       "         [   0,   11,    3,  ...,    2,    2,    2],\n",
       "         [   0,    4,   69,  ...,    2,    2,    2],\n",
       "         ...,\n",
       "         [   0,  553,    5,  ...,    2,    2,    2],\n",
       "         [   0,    4, 8442,  ...,    2,    2,    2],\n",
       "         [   0,  670,    4,  ...,    2,    2,    2]]),\n",
       " tensor([[   0,  298,   17,  ...,    2,    2,    2],\n",
       "         [   0, 3462,  239,  ...,    2,    2,    2],\n",
       "         [   0,  733,   75,  ...,    2,    2,    2],\n",
       "         ...,\n",
       "         [   0,    9,  298,  ...,    2,    2,    2],\n",
       "         [   0,   59, 2459,  ...,    2,    2,    2],\n",
       "         [   0,  298, 6566,  ...,    2,    2,    2]])]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
